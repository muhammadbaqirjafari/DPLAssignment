{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Credit Card Fraud Detection assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud8NGbov5ISx"
      },
      "source": [
        "# Credit Card Fraud Detection::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxkphJNJ5IS7"
      },
      "source": [
        "Download dataset from this link:\n",
        "\n",
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NIgAkcm5IS7"
      },
      "source": [
        "# Description about dataset::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch0nrcrm5IS8"
      },
      "source": [
        "The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n",
        "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, â€¦ V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
        "\n",
        "\n",
        "### Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjMWP6tb5IS8"
      },
      "source": [
        "# WORKFLOW :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x57vMM6n5IS9"
      },
      "source": [
        "1.Load Data\n",
        "\n",
        "2.Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "\n",
        "3.Standardized the Input Variables. \n",
        "\n",
        "4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "\n",
        "5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "\n",
        "6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
        "\n",
        "7.Train the Model with Epochs (100).\n",
        "\n",
        "8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "\n",
        "9.Prediction should be > 92%\n",
        "10.Evaluation Step\n",
        "11Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTJ6eiGN5IS9"
      },
      "source": [
        "# Task::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN3Xour25IS-"
      },
      "source": [
        "## Identify fraudulent credit card transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MpamcZb5x73"
      },
      "source": [
        "1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "HpnJ-6su9vlW",
        "outputId": "84754ae4-98dc-4ee4-adbd-aeec08348c67"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/kaggle/creditcardfraud/creditcard.csv\")\n",
        "# Displaying\n",
        "data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTSSeTj51Y6"
      },
      "source": [
        "2. Check Missing Values ( If Exist ; Fill each record with mean of its feature )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmUzvXYwAwlP",
        "outputId": "dc3a8f08-7a89-4140-818a-bc88725ead8c"
      },
      "source": [
        "# Checking NaN Values\n",
        "for column in data.columns:\n",
        "  print(column, np.isnan(data[column]).sum())\n",
        "# So there is no NaN value"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time 0\n",
            "V1 0\n",
            "V2 0\n",
            "V3 0\n",
            "V4 0\n",
            "V5 0\n",
            "V6 0\n",
            "V7 0\n",
            "V8 0\n",
            "V9 0\n",
            "V10 0\n",
            "V11 0\n",
            "V12 0\n",
            "V13 0\n",
            "V14 0\n",
            "V15 0\n",
            "V16 0\n",
            "V17 0\n",
            "V18 0\n",
            "V19 0\n",
            "V20 0\n",
            "V21 0\n",
            "V22 0\n",
            "V23 0\n",
            "V24 0\n",
            "V25 0\n",
            "V26 0\n",
            "V27 0\n",
            "V28 0\n",
            "Amount 0\n",
            "Class 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMbHi2Gy5-mS"
      },
      "source": [
        "3. Standardized the Input Variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPgoY2665IS_"
      },
      "source": [
        "x = data.loc[:, 'V1':'V28'] # Input\n",
        "y = data['Class'] # Output"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO8hLEH16Cir"
      },
      "source": [
        "4. Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa7-I_7Z5IS_",
        "outputId": "f63da9ec-31b7-4274-fc98-431c87f68b08"
      },
      "source": [
        "length = len(x)\n",
        "\n",
        "# 50% Training\n",
        "x_train = x.loc[0: length/2]\n",
        "y_train = y.loc[0: length/2]\n",
        "\n",
        "# 30% Test\n",
        "x_test = x.loc[length/2 + 1: 4/5*length]\n",
        "y_test = y.loc[length/2 +1: 4/5*length]\n",
        "\n",
        "# 20% Validation\n",
        "x_validate = x.loc[4/5*length + 1:]\n",
        "y_validate = y.loc[4/5*length + 1:]\n",
        "\n",
        "# Checking\n",
        "print(len(x_train)/length, len(x_test)/length, len(x_validate)/length)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5000017555748278 0.2999961377353787 0.19999508439048197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0qF1ujZ6Ftc"
      },
      "source": [
        "5. Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRGvyZ-u5IS_"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(28, activation='relu', input_shape=(28, ))) # Input Layer\n",
        "model.add(layers.Dense(10, activation='relu')) # Hidden Layer 1\n",
        "model.add(layers.Dense(8, activation='relu')) # Hidden Layer 2\n",
        "model.add(layers.Dense(6, activation='relu')) # Hidden Layer 3\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # Output Layer"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op6EBX5c6Ix_"
      },
      "source": [
        "6. Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo8dhd565IS_"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9q8Sx9-6LzS"
      },
      "source": [
        "7. Train the Model with Epochs (100)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxesbV1x5ITA",
        "outputId": "ed0ccf3e-ef50-4954-d2c3-c7e61a8be90c"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=100, batch_size=512, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0220 - val_accuracy: 0.9949\n",
            "Epoch 2/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0215 - val_accuracy: 0.9949\n",
            "Epoch 3/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0210 - val_accuracy: 0.9957\n",
            "Epoch 4/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0217 - val_accuracy: 0.9949\n",
            "Epoch 5/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0256 - val_accuracy: 0.9941\n",
            "Epoch 6/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0269 - val_accuracy: 0.9938\n",
            "Epoch 7/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.6348e-04 - accuracy: 0.9998 - val_loss: 0.0255 - val_accuracy: 0.9948\n",
            "Epoch 8/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0274 - val_accuracy: 0.9943\n",
            "Epoch 9/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0350 - val_accuracy: 0.9928\n",
            "Epoch 10/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0288 - val_accuracy: 0.9943\n",
            "Epoch 11/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0262 - val_accuracy: 0.9949\n",
            "Epoch 12/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.9216e-04 - accuracy: 0.9998 - val_loss: 0.0301 - val_accuracy: 0.9941\n",
            "Epoch 13/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0332 - val_accuracy: 0.9931\n",
            "Epoch 14/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0313 - val_accuracy: 0.9940\n",
            "Epoch 15/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.6432e-04 - accuracy: 0.9998 - val_loss: 0.0348 - val_accuracy: 0.9934\n",
            "Epoch 16/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0372 - val_accuracy: 0.9915\n",
            "Epoch 17/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.7527e-04 - accuracy: 0.9998 - val_loss: 0.0325 - val_accuracy: 0.9940\n",
            "Epoch 18/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.5390e-04 - accuracy: 0.9998 - val_loss: 0.0334 - val_accuracy: 0.9936\n",
            "Epoch 19/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.4175e-04 - accuracy: 0.9998 - val_loss: 0.0342 - val_accuracy: 0.9932\n",
            "Epoch 20/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0327 - val_accuracy: 0.9939\n",
            "Epoch 21/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.5208e-04 - accuracy: 0.9998 - val_loss: 0.0386 - val_accuracy: 0.9916\n",
            "Epoch 22/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.9798e-04 - accuracy: 0.9998 - val_loss: 0.0431 - val_accuracy: 0.9915\n",
            "Epoch 23/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.2473e-04 - accuracy: 0.9998 - val_loss: 0.0531 - val_accuracy: 0.9871\n",
            "Epoch 24/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.6929e-04 - accuracy: 0.9998 - val_loss: 0.0549 - val_accuracy: 0.9875\n",
            "Epoch 25/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.1658e-04 - accuracy: 0.9998 - val_loss: 0.0436 - val_accuracy: 0.9909\n",
            "Epoch 26/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.2409e-04 - accuracy: 0.9998 - val_loss: 0.0547 - val_accuracy: 0.9857\n",
            "Epoch 27/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0697 - val_accuracy: 0.9794\n",
            "Epoch 28/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 9.2110e-04 - accuracy: 0.9998 - val_loss: 0.0604 - val_accuracy: 0.9848\n",
            "Epoch 29/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.6047e-04 - accuracy: 0.9998 - val_loss: 0.0489 - val_accuracy: 0.9912\n",
            "Epoch 30/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.6921e-04 - accuracy: 0.9998 - val_loss: 0.0616 - val_accuracy: 0.9854\n",
            "Epoch 31/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.9910e-04 - accuracy: 0.9998 - val_loss: 0.0598 - val_accuracy: 0.9867\n",
            "Epoch 32/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.7103e-04 - accuracy: 0.9998 - val_loss: 0.0595 - val_accuracy: 0.9839\n",
            "Epoch 33/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.5914e-04 - accuracy: 0.9998 - val_loss: 0.0910 - val_accuracy: 0.9767\n",
            "Epoch 34/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.8780e-04 - accuracy: 0.9998 - val_loss: 0.0740 - val_accuracy: 0.9780\n",
            "Epoch 35/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.7490e-04 - accuracy: 0.9998 - val_loss: 0.0564 - val_accuracy: 0.9885\n",
            "Epoch 36/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.7947e-04 - accuracy: 0.9998 - val_loss: 0.0962 - val_accuracy: 0.9718\n",
            "Epoch 37/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.8717e-04 - accuracy: 0.9998 - val_loss: 0.0920 - val_accuracy: 0.9721\n",
            "Epoch 38/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.2130e-04 - accuracy: 0.9998 - val_loss: 0.0834 - val_accuracy: 0.9765\n",
            "Epoch 39/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.2409e-04 - accuracy: 0.9998 - val_loss: 0.0817 - val_accuracy: 0.9754\n",
            "Epoch 40/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.8421e-04 - accuracy: 0.9998 - val_loss: 0.1236 - val_accuracy: 0.9633\n",
            "Epoch 41/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.9300e-04 - accuracy: 0.9998 - val_loss: 0.0866 - val_accuracy: 0.9738\n",
            "Epoch 42/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.3946e-04 - accuracy: 0.9998 - val_loss: 0.1206 - val_accuracy: 0.9639\n",
            "Epoch 43/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.1637e-04 - accuracy: 0.9998 - val_loss: 0.0993 - val_accuracy: 0.9721\n",
            "Epoch 44/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.5961e-04 - accuracy: 0.9998 - val_loss: 0.1056 - val_accuracy: 0.9705\n",
            "Epoch 45/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.9937e-04 - accuracy: 0.9998 - val_loss: 0.1382 - val_accuracy: 0.9595\n",
            "Epoch 46/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.2852e-04 - accuracy: 0.9998 - val_loss: 0.1248 - val_accuracy: 0.9634\n",
            "Epoch 47/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.9577e-04 - accuracy: 0.9998 - val_loss: 0.1391 - val_accuracy: 0.9590\n",
            "Epoch 48/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.0105e-04 - accuracy: 0.9998 - val_loss: 0.1053 - val_accuracy: 0.9707\n",
            "Epoch 49/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.1034e-04 - accuracy: 0.9998 - val_loss: 0.1405 - val_accuracy: 0.9582\n",
            "Epoch 50/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.6107e-04 - accuracy: 0.9998 - val_loss: 0.0937 - val_accuracy: 0.9736\n",
            "Epoch 51/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1201 - val_accuracy: 0.9657\n",
            "Epoch 52/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.8536e-04 - accuracy: 0.9998 - val_loss: 0.1306 - val_accuracy: 0.9621\n",
            "Epoch 53/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.5078e-04 - accuracy: 0.9998 - val_loss: 0.1699 - val_accuracy: 0.9518\n",
            "Epoch 54/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.0288e-04 - accuracy: 0.9998 - val_loss: 0.1507 - val_accuracy: 0.9591\n",
            "Epoch 55/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.3561e-04 - accuracy: 0.9998 - val_loss: 0.1756 - val_accuracy: 0.9521\n",
            "Epoch 56/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.0807e-04 - accuracy: 0.9998 - val_loss: 0.1577 - val_accuracy: 0.9564\n",
            "Epoch 57/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.5355e-04 - accuracy: 0.9997 - val_loss: 0.1702 - val_accuracy: 0.9567\n",
            "Epoch 58/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.5292e-04 - accuracy: 0.9998 - val_loss: 0.1777 - val_accuracy: 0.9512\n",
            "Epoch 59/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.3664e-04 - accuracy: 0.9998 - val_loss: 0.1302 - val_accuracy: 0.9669\n",
            "Epoch 60/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.7375e-04 - accuracy: 0.9998 - val_loss: 0.1486 - val_accuracy: 0.9595\n",
            "Epoch 61/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.8979e-04 - accuracy: 0.9998 - val_loss: 0.1987 - val_accuracy: 0.9454\n",
            "Epoch 62/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.3343e-04 - accuracy: 0.9998 - val_loss: 0.1380 - val_accuracy: 0.9589\n",
            "Epoch 63/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.4199e-04 - accuracy: 0.9998 - val_loss: 0.1651 - val_accuracy: 0.9560\n",
            "Epoch 64/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.2192e-04 - accuracy: 0.9998 - val_loss: 0.1700 - val_accuracy: 0.9508\n",
            "Epoch 65/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.1398e-04 - accuracy: 0.9998 - val_loss: 0.1594 - val_accuracy: 0.9557\n",
            "Epoch 66/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.6571e-04 - accuracy: 0.9998 - val_loss: 0.1659 - val_accuracy: 0.9576\n",
            "Epoch 67/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.8182e-04 - accuracy: 0.9998 - val_loss: 0.1605 - val_accuracy: 0.9575\n",
            "Epoch 68/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.0879e-04 - accuracy: 0.9998 - val_loss: 0.1916 - val_accuracy: 0.9452\n",
            "Epoch 69/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.2954e-04 - accuracy: 0.9998 - val_loss: 0.1275 - val_accuracy: 0.9647\n",
            "Epoch 70/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.9757e-04 - accuracy: 0.9998 - val_loss: 0.1631 - val_accuracy: 0.9525\n",
            "Epoch 71/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.1313e-04 - accuracy: 0.9998 - val_loss: 0.1685 - val_accuracy: 0.9519\n",
            "Epoch 72/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.5984e-04 - accuracy: 0.9998 - val_loss: 0.1258 - val_accuracy: 0.9655\n",
            "Epoch 73/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.4383e-04 - accuracy: 0.9998 - val_loss: 0.1324 - val_accuracy: 0.9635\n",
            "Epoch 74/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.5121e-04 - accuracy: 0.9998 - val_loss: 0.1620 - val_accuracy: 0.9561\n",
            "Epoch 75/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.2461e-04 - accuracy: 0.9998 - val_loss: 0.1799 - val_accuracy: 0.9507\n",
            "Epoch 76/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.3286e-04 - accuracy: 0.9998 - val_loss: 0.1705 - val_accuracy: 0.9533\n",
            "Epoch 77/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.7898e-04 - accuracy: 0.9997 - val_loss: 0.2233 - val_accuracy: 0.9426\n",
            "Epoch 78/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.9965e-04 - accuracy: 0.9998 - val_loss: 0.1605 - val_accuracy: 0.9597\n",
            "Epoch 79/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.0367e-04 - accuracy: 0.9998 - val_loss: 0.1945 - val_accuracy: 0.9525\n",
            "Epoch 80/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.6840e-04 - accuracy: 0.9998 - val_loss: 0.2171 - val_accuracy: 0.9476\n",
            "Epoch 81/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.2849e-04 - accuracy: 0.9998 - val_loss: 0.2807 - val_accuracy: 0.9340\n",
            "Epoch 82/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.5834e-04 - accuracy: 0.9998 - val_loss: 0.2203 - val_accuracy: 0.9466\n",
            "Epoch 83/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.1537e-04 - accuracy: 0.9998 - val_loss: 0.2240 - val_accuracy: 0.9470\n",
            "Epoch 84/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 5.7023e-04 - accuracy: 0.9998 - val_loss: 0.2029 - val_accuracy: 0.9500\n",
            "Epoch 85/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 8.1535e-04 - accuracy: 0.9998 - val_loss: 0.2150 - val_accuracy: 0.9483\n",
            "Epoch 86/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 5.5315e-04 - accuracy: 0.9999 - val_loss: 0.1983 - val_accuracy: 0.9530\n",
            "Epoch 87/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.7670e-04 - accuracy: 0.9998 - val_loss: 0.2158 - val_accuracy: 0.9490\n",
            "Epoch 88/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1856 - val_accuracy: 0.9542\n",
            "Epoch 89/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 5.9635e-04 - accuracy: 0.9999 - val_loss: 0.2006 - val_accuracy: 0.9550\n",
            "Epoch 90/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.3534e-04 - accuracy: 0.9998 - val_loss: 0.2445 - val_accuracy: 0.9465\n",
            "Epoch 91/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.0508e-04 - accuracy: 0.9998 - val_loss: 0.2242 - val_accuracy: 0.9503\n",
            "Epoch 92/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.5695e-04 - accuracy: 0.9998 - val_loss: 0.2631 - val_accuracy: 0.9415\n",
            "Epoch 93/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.4446e-04 - accuracy: 0.9998 - val_loss: 0.1898 - val_accuracy: 0.9546\n",
            "Epoch 94/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 5.8998e-04 - accuracy: 0.9998 - val_loss: 0.2627 - val_accuracy: 0.9449\n",
            "Epoch 95/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.3037e-04 - accuracy: 0.9998 - val_loss: 0.2045 - val_accuracy: 0.9534\n",
            "Epoch 96/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.4903e-04 - accuracy: 0.9998 - val_loss: 0.2028 - val_accuracy: 0.9570\n",
            "Epoch 97/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 6.6161e-04 - accuracy: 0.9998 - val_loss: 0.2523 - val_accuracy: 0.9478\n",
            "Epoch 98/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.8557e-04 - accuracy: 0.9999 - val_loss: 0.2420 - val_accuracy: 0.9494\n",
            "Epoch 99/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.6311e-04 - accuracy: 0.9998 - val_loss: 0.2234 - val_accuracy: 0.9521\n",
            "Epoch 100/100\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 7.3916e-04 - accuracy: 0.9998 - val_loss: 0.2151 - val_accuracy: 0.9547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdGxnoK6PNj"
      },
      "source": [
        "8. If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "x7jOjL_i5ITA",
        "outputId": "d80a5a9f-420a-4261-8592-240ce08f8bc4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss') # bo is for blue dot\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') # b is for solid blue line\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kScinE0KPLVJ",
        "outputId": "34e2bd08-5bef-45e2-8ef2-f79685808820"
      },
      "source": [
        "# Changing the layers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(28, ))) # Input Layer\n",
        "model.add(layers.Dense(8, activation='relu')) # Hidden Layer 3\n",
        "model.add(layers.Dense(1, activation='sigmoid')) # Output Layer\n",
        "# Complilatin\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Epochs 4(after experiment)\n",
        "history = model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "279/279 [==============================] - 1s 2ms/step - loss: 0.2308 - accuracy: 0.9799 - val_loss: 0.0139 - val_accuracy: 0.9987\n",
            "Epoch 2/4\n",
            "279/279 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
            "Epoch 3/4\n",
            "279/279 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "279/279 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0068 - val_accuracy: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBAeL0EL6S4z"
      },
      "source": [
        "9. Prediction should be > 92%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI13lNyU6WSd"
      },
      "source": [
        "10. Evaluation Step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AojovKdz5ITA",
        "outputId": "41610452-7f38-4a80-b7c8-019fcd7cbe82"
      },
      "source": [
        "model.evaluate(x_test, y_test) # 99% Accuracy"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2671/2671 [==============================] - 2s 840us/step - loss: 0.0071 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.007110022474080324, 0.9994148015975952]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    }
  ]
}